# prompts = {
#     "chief_complaint": "Please describe the main reason for your visit today.",
#     "history_of_present_illness": "Detail the timeline of your current symptoms, starting from when they first appeared.",
#     "past_medical_history": "Do you have any ongoing medical conditions or a history of any diseases?",
#     "drug_history": "What medications are you currently taking, and do you have any known allergies?",
#     "family_history": "Is there a history of any genetic diseases in your family?",
#     "social_history": "Can you provide important information related to your social circumstances, such as smoking or alcohol consumption?",
#     "recent_tests": "Do you have any recent medical tests or documents? If so, please upload a photo of the documents."
# }

# from openai import OpenAI
# import re

# client = OpenAI(
#     base_url = "https://api.scaleway.ai/74bb05fa-56e4-49d4-949a-fabc5875d712/v1",
#     api_key = "35465751-64a0-4d1e-87aa-fd326c191da1" # Replace SCW_SECRET_KEY with your IAM API key
# )

# def remove_think_tags(text):
#     # This pattern will match text enclosed in <think>...</think>
#     pattern = r"<think>.*?</think>"
#     # Replace the matched text with an empty string
#     new_text = re.sub(pattern, '', text, flags=re.DOTALL)
#     return new_text

# # def get_contant_from_deepseek(prompt, max_token=512):
# #     """Uses DeepSeek AI to summarize"""
# #     prompt = prompt

# #     response = client.chat.completions.create(
# #         model="deepseek-r1",
# #         messages=[{"role": "system", "content": 'you are a AI in medical field'},
# #                     {"role": "user", "content": prompt}],
# #         max_tokens=max_token,
# #         temperature=0.6,
# #         top_p=0.95
# #     )

# #     output_model = remove_think_tags(response.choices[0].message.content)

# #     return output_model


# def get_contant_from_deepseek(prompt, max_token):
#     """Generate a medical domain text summary using DeepSeek AI
    
#     Args:
#         prompt: Input prompt text
#         max_token: Maximum token count for generated text
        
#     Returns:
#         str: Processed content generated by the model
#     """
#     response = client.chat.completions.create(
#         model="deepseek-r1",
#         messages=[
#             {"role": "system", "content": "You are an AI specialized in the medical field"},
#             {"role": "user", "content": prompt}  # Fixed parameter name
#         ],
#         max_tokens=max_token,  # Using the provided max_token parameter
#         temperature=0.6,
#         top_p=0.95
#     )

#     return remove_think_tags(response.choices[0].message.content)

# def first_summary(the_dict_of_q_and_a, length=4096):
#     """Generate a preliminary medical summary
    
#     Args:
#         the_dict_of_q_and_a: Dictionary containing doctor-patient Q&A in the format {question: answer}
        
#     Returns:
#         str: Preliminary summary result; if there are no Q&A, returns 'No questions to summarize'
#     """
#     if not the_dict_of_q_and_a:
#         return 'No questions to summarize'
    
#     # Construct prompt in Q&A format
#     qa_list = [f"[Question]{q}\n[Answer]{a}" for q, a in the_dict_of_q_and_a.items()]
#     prompt = (
#         "Based on the following doctor-patient conversation:\n" +
#         "\n\n".join(qa_list) +
#         " You only need to reply with one question. This question should address any parts that the patient has not expressed clearly. Your question must be concise. If you feel the patient has expressed everything clearly, you may respond with 'Is there anything else you'd like to add?'"
#         " You must ask in English"
#     )
    
#     return get_contant_from_deepseek(prompt, length)  # Control the generation length

# def final_summary(the_dict_of_q_and_a, length=4096):
#     """Generate the final medical report and health score
    
#     Args:
#         the_dict_of_q_and_a: Dictionary containing complete doctor-patient Q&A
        
#     Returns:
#         tuple: (Final report text, Health score from 1 to 10)
#     """
#     if not the_dict_of_q_and_a:
#         return 'The patient has not reported any health issues at this time', 1
    
#     # Construct detailed prompt
#     qa_list = [f"[Question]{q}\n[Answer]{a}" for q, a in the_dict_of_q_and_a.items()]
#     prompt = (
#         "Please generate a final medical report that includes the following elements:\n"
#         "1. Summary of symptoms\n2. Analysis of potential risks\n3. Recommended examinations\n"
#         "4. At the beginning of the report, provide a health score in the format [score: x] (1-10, where 1 is the healthiest)\n\n"
#         "Patient Q&A record:\n" + "\n\n".join(qa_list) +
#         " Please note that your analysis is intended for both the patient and the doctor, so it should be concise and professional for their understanding. Also, note that you should think quickly and your output should be brief. You must answer in English"
#     )
    
#     # Obtain content generated by the model
#     raw_output = get_contant_from_deepseek(prompt, length)
#     raw_output = remove_think_tags(raw_output)
    
#     # Parse the score from the content
#     score = 1
#     try:
#         pattern = r'\[score:\s*(\d+)\]'
#         score_match = re.search(pattern, raw_output)
#         if score_match:
#             score = min(max(int(score_match.group(1)), 1), 10)  # Ensure the score is between 1 and 10
#             report = re.sub(r'[score: \d+]', '', raw_output).strip()
#         else:
#             report = raw_output
#             score = 1  # Default score
#     except:
#         score = 1
#         report = raw_output

#     # report = remove_think_tags(raw_output)
    
#     return report, score
#----------------------------------------------------------------


import streamlit as st
import fitz  # PyMuPDF for PDF processing
from openai import OpenAI
import re

client = OpenAI(
    base_url = "https://api.scaleway.ai/74bb05fa-56e4-49d4-949a-fabc5875d712/v1",
    api_key = "35465751-64a0-4d1e-87aa-fd326c191da1" # Replace SCW_SECRET_KEY with your IAM API key
)

# ‚úÖ Medical Question Prompts
prompts = {
    "chief_complaint": "Please describe the main reason for your visit today.",
    "history_of_present_illness": "Detail the timeline of your current symptoms, starting from when they first appeared.",
    "past_medical_history": "Do you have any ongoing medical conditions or a history of any diseases?",
    "drug_history": "What medications are you currently taking, and do you have any known allergies?",
    "family_history": "Is there a history of any genetic diseases in your family?",
    "social_history": "Do you smoke or consume alcohol regularly?",
    "recent_tests": "Do you have any recent medical tests or documents? If so, please upload a pathology report."
}

# ‚úÖ Function to Remove AI "Thinking" Sections
def remove_think_tags(text):
    """Removes <think> tags from AI responses."""
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

# ‚úÖ Function to Extract Text from PDF
def extract_text_from_pdf(uploaded_file):
    """Extracts text from an uploaded PDF file."""
    try:
        pdf_bytes = uploaded_file.getbuffer().tobytes()
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        return "\n".join([page.get_text("text") for page in doc])
    except Exception as e:
        st.error(f"‚ùå Error processing PDF: {str(e)}")
        return "ERROR: Could not process the PDF."

# ‚úÖ Function to Extract Key Medical Findings
def extract_key_findings(pdf_text):
    """Extracts key lab values and abnormalities using Mistral AI."""
    prompt = f"""
    Extract **key medical findings** from the following **blood report**:

    **Medical Report:**
    {pdf_text[:2000]}

    Format output as:
    - üî¥ **Critical Findings:** [Lab Test]: [Value] (Normal Range: [Range])
    - üü° **Moderate Findings:** [Lab Test]: [Value] (Normal Range: [Range])
    - üü¢ **Normal Findings:** [Lab Test]: [Value] (Normal Range: [Range])
    """

    response = client.chat.completions.create(
        model="mistral-nemo-instruct-2407",
        messages=[{"role": "system", "content": "You are a structured medical AI assistant."},
                  {"role": "user", "content": prompt}],
        max_tokens=500
    )

    return remove_think_tags(response.choices[0].message.content.strip())

# ‚úÖ Function to Generate a Medical Summary
def summarize_disease(the_dict_of_q_and_a, key_findings):
    """Generates a structured summary of the patient‚Äôs condition."""
    qa_list = [f"[Question]{q}\n[Answer]{a}" for q, a in the_dict_of_q_and_a.items()]
    prompt = f"""
    Summarize the patient‚Äôs condition based on:
    - **Lab Report Findings**: {key_findings}
    - **Patient's Medical History**: {', '.join(qa_list)}

    Provide a **clear, structured summary** in bullet points.
    """

    response = client.chat.completions.create(
        model="mistral-nemo-instruct-2407",
        messages=[{"role": "system", "content": "You are a concise medical AI assistant."},
                  {"role": "user", "content": prompt}],
        max_tokens=400
    )

    return remove_think_tags(response.choices[0].message.content.strip())

# ‚úÖ Function to Analyze Case Severity
def analyze_lab_severity(key_findings):
    """Determines case severity & highlights critical values using Mistral."""
    prompt = f"""
    Analyze **severity of the patient‚Äôs case** based on the following findings:

    **Findings:**
    {key_findings}

    Classify severity as:
    - üü¢ **Mild**
    - üü° **Moderate**
    - üî¥ **Severe**

    Also, list **specific lab values that are extremely high or low**.
    """

    response = client.chat.completions.create(
        model="mistral-nemo-instruct-2407",
        messages=[{"role": "system", "content": "You are a severity analysis AI."},
                  {"role": "user", "content": prompt}],
        max_tokens=400
    )

    return remove_think_tags(response.choices[0].message.content.strip())

# ‚úÖ Function to Recommend a Specialist
def recommend_specialist(summary):
    """Suggests the most relevant specialist based on the medical summary."""
    prompt = f"""
    Based on the **medical summary**, recommend the **best specialist** for the patient:

    **Summary:**
    {summary}

    Choose one:
    - **General Physician**
    - **Diabetologist**
    - **Cardiologist**
    - **Neurologist**
    """

    response = client.chat.completions.create(
        model="mistral-nemo-instruct-2407",
        messages=[{"role": "system", "content": "You are a specialist recommendation AI."},
                  {"role": "user", "content": prompt}],
        max_tokens=50
    )

    return response.choices[0].message.content.strip()

# ‚úÖ Streamlit Chatbot UI
st.title("üí¨ AI Medical Chatbot")

# Initialize session state for chat history
if "qa_history" not in st.session_state:
    st.session_state.qa_history = {}

# **Start Medical Consultation**
if not st.session_state.qa_history:
    current_question = list(prompts.keys())[0]
else:
    current_question = list(prompts.keys())[len(st.session_state.qa_history)] if len(st.session_state.qa_history) < len(prompts) else None

# Display previous questions & answers
for q, a in st.session_state.qa_history.items():
    st.write(f"‚ùì **{q}:** {a}")

# Ask new question
if current_question:
    st.subheader(f"üìå {prompts[current_question]}")
    user_response = st.text_input("Your answer:", key=f"input_{current_question}")

    if user_response:
        st.session_state.qa_history[current_question] = user_response
        st.rerun()  # Refresh UI to show next question

# **File Upload for Medical Report**
uploaded_file = st.file_uploader("üìÑ Upload Pathology Report (PDF)", type="pdf")

# **Analyze Medical Data if Complete**
if len(st.session_state.qa_history) == len(prompts) and uploaded_file:
    st.subheader("üîç Extracting Medical Report...")
    pdf_text = extract_text_from_pdf(uploaded_file)

    if "ERROR" in pdf_text:
        st.error("üö® Failed to process the PDF.")
    else:
        st.success("‚úÖ PDF processed successfully!")

        # Extract Key Findings
        key_findings = extract_key_findings(pdf_text)
        st.subheader("üîç Key Medical Findings")
        st.write(key_findings)

        # Generate Summary
        summary = summarize_disease(st.session_state.qa_history, key_findings)
        st.subheader("üìù Medical Summary")
        st.write(summary)

        # Analyze Severity
        severity_analysis = analyze_lab_severity(key_findings)
        st.subheader("üö® Severity Analysis")
        st.write(severity_analysis)

        # Recommend Specialist
        recommended_specialist = recommend_specialist(summary)
        st.subheader("üë®‚Äç‚öïÔ∏è Recommended Specialist")
        st.success(f"**{recommended_specialist}**")
